{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finger Detection Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install Requirement Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Nesscessary Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green\n",
    "\n",
    "# Define indices for fingertips and key landmarks\n",
    "FINGER_TIPS = [4, 8, 12, 16, 20]  # Thumb, Index, Middle, Ring, Pinky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for check the finger is open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_finger_extended(hand_landmarks, tip_idx, lower_idx):\n",
    "    \"\"\"\n",
    "    Check if a finger is extended by comparing the y-coordinate (height)\n",
    "    of the fingertip and its lower joint.\n",
    "    \"\"\"\n",
    "    # Print the y-coordinates of the fingertip and lower joint\n",
    "    # print(f\"tip_idx.y ({tip_idx}): {hand_landmarks[tip_idx].y}\")\n",
    "    # print(f\"lower_idx.y ({lower_idx}): {hand_landmarks[lower_idx].y}\")\n",
    "    \n",
    "    return hand_landmarks[tip_idx].y < hand_landmarks[lower_idx].y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check hand is outward or inward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(hand_landmarks):\n",
    "    \"\"\"\n",
    "    Detect whether the palm is facing inwards or outwards based on landmark positions.\n",
    "    \"\"\"\n",
    "    # Key palm and finger landmarks\n",
    "    wrist_z = hand_landmarks[0].z\n",
    "    middle_finger_tip_z = hand_landmarks[12].z\n",
    "    index_finger_tip_z = hand_landmarks[8].z\n",
    "    middle_finger_mcp_z = hand_landmarks[9].z\n",
    "\n",
    "    # Calculate average z-coordinates for palm and fingertips\n",
    "    palm_z_average = (wrist_z + middle_finger_mcp_z) / 2\n",
    "    fingertips_z_average = (middle_finger_tip_z + index_finger_tip_z) / 2\n",
    "\n",
    "    # Detect palm orientation\n",
    "    if palm_z_average > fingertips_z_average:\n",
    "        print('Palm Outwards')\n",
    "        return 1  # Palm facing outwards\n",
    "    else:\n",
    "        print('Palm Inwards')\n",
    "        return 2  # Palm facing inwards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for count finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fingers(hand_landmarks, handedness_label):\n",
    "    \"\"\"\n",
    "    Count the number of extended fingers for a detected hand.\n",
    "    Works with different palm orientations.\n",
    "    \"\"\"\n",
    "    extended_fingers = 0\n",
    "\n",
    "    # Check non-thumb fingers\n",
    "    for tip_idx in FINGER_TIPS[1:]:  # Skip the thumb\n",
    "        lower_joint_idx = tip_idx - 2\n",
    "        if is_finger_extended(hand_landmarks, tip_idx, lower_joint_idx):\n",
    "            extended_fingers += 1\n",
    "\n",
    "    # Improved thumb detection using 3D coordinates\n",
    "    thumb_tip = hand_landmarks[FINGER_TIPS[0]]\n",
    "    thumb_ip = hand_landmarks[FINGER_TIPS[0] - 1]  # IP joint\n",
    "    thumb_mcp = hand_landmarks[FINGER_TIPS[0] - 2]  # MCP joint\n",
    "    pinky_mcp = hand_landmarks[17]  # Pinky MCP joint\n",
    "\n",
    "    # Calculate vectors\n",
    "    vector_thumb = np.array([thumb_tip.x - thumb_ip.x, \n",
    "                           thumb_tip.y - thumb_ip.y, \n",
    "                           thumb_tip.z - thumb_ip.z])\n",
    "    vector_palm = np.array([pinky_mcp.x - thumb_mcp.x,\n",
    "                          pinky_mcp.y - thumb_mcp.y,\n",
    "                          pinky_mcp.z - thumb_mcp.z])\n",
    "    \n",
    "    # Normalize vectors\n",
    "    vector_thumb = vector_thumb / np.linalg.norm(vector_thumb)\n",
    "    vector_palm = vector_palm / np.linalg.norm(vector_palm)\n",
    "    \n",
    "    # Calculate angle between thumb and palm\n",
    "    angle = np.arccos(np.clip(np.dot(vector_thumb, vector_palm), -1.0, 1.0))\n",
    "    angle_degrees = np.degrees(angle)\n",
    "\n",
    "    # If angle is greater than threshold, thumb is considered extended\n",
    "    if angle_degrees > 35:  # You may need to adjust this threshold\n",
    "        extended_fingers += 1\n",
    "\n",
    "    return extended_fingers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for draw land mark count finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_and_count_fingers(rgb_image, results):\n",
    "\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    height, width, _ = annotated_image.shape\n",
    "\n",
    "    total_finger_count = 0  # Initialize total finger count\n",
    "\n",
    "    for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "        handedness_label = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "        # Draw hand landmarks\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks,\n",
    "            solutions.hands.HAND_CONNECTIONS,\n",
    "            solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "            solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        # Count extended fingers for the current hand\n",
    "        finger_count = count_fingers(hand_landmarks.landmark, handedness_label)\n",
    "        total_finger_count += finger_count  # Add to total finger count\n",
    "\n",
    "        # Get bounding box for text placement\n",
    "        x_coordinates = [lm.x for lm in hand_landmarks.landmark]\n",
    "        y_coordinates = [lm.y for lm in hand_landmarks.landmark]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        # Display handedness and finger count\n",
    "        cv2.putText(annotated_image,\n",
    "                    f\"{handedness_label}: {finger_count} fingers\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    # Display total finger count at the top of the image\n",
    "    total_count_text = f\"Total: {total_finger_count}\"\n",
    "    cv2.putText(annotated_image,\n",
    "                total_count_text,\n",
    "                (10, 30),  # Top-left corner\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                FONT_SIZE, (255, 0, 0), FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize Mediapipe Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735829621.212557   14547 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1735829621.216128   14863 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.3), renderer: Mesa Intel(R) UHD Graphics (TGL GT1)\n"
     ]
    }
   ],
   "source": [
    "mp_hands = solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Video for Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735829621.268634   14850 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1735829621.303448   14852 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/panha/Desktop/Rupp/Year_4/PP/finger_counter/env/lib/python3.12/site-packages/cv2/qt/plugins\"\n",
      "W0000 00:00:1735829624.434431   14849 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "wCam, hCam = 700, 700\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip frame horizontally for mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Annotate frame if hands are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        frame = draw_landmarks_and_count_fingers(frame, results)\n",
    "\n",
    "    # Display annotated frame\n",
    "    cv2.imshow('Finger Count', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
